import ast
import asyncio
import random

from tqdm.asyncio import tqdm

async def in_context_beam_search(prediction_info: str, model_call):
    content = """
I have a noisy speech recognition system which predicts 64 words at a time. I am going to give you its predictions in an ordered list of pairs (word, probability). For each position, I give you the top-5 word predictions ordered from most likely to least likely along with their probabilities. [UNK] indicates that the target word for that position is out-of-vocabulary.

I want you to predict the most likely sequence from this information, picking the words from the predictions for each position that go best together. Where there is an [UNK] I want you to replace it with your own prediction for a word that fits well. In places with no [UNK], your job is to just pick the best fitting word from the predictions list (do not use any other word). Your output should be formatted as a Python dictionary mapping all 64 positions (0-indexed) to words. Do not output anything else.

Output example:
{0: "don't", 1: "the", 2: "scowl", ..., 63: "if"}

Predictions from speech recognition system:
"""
    message = content + "\n" + prediction_info
    response = await model_call(message)
    response = response.strip()

    try:
        # Parse response as Python dictionary
        response = ast.literal_eval(response)
        assert isinstance(response, dict), "Response is not a dictionary"
        sentence = " ".join([response[i] for i in range(64)])
        return sentence.strip().lower()
    except Exception as e:
        print(f"Error parsing response: {e}")
        print("Response:", response)
        return "Error parsing response"


async def batch_in_context_beam_search(prediction_infos: list[str], model_call):
    tasks = [in_context_beam_search(prediction_info, model_call) for prediction_info in prediction_infos]
    return await tqdm.gather(*tasks)

async def pick_best_sentence(sentences: list[str], model_call):

    sentences = '\n'.join(sentences)

    content = f"You are helping me select the single best predicted sentence from candidates generated by a very low quality speech recognition system. The system may have made many mistakes. You will see a list of predictions, one on each line. I want you to think about the semantic content of each sentence and decide which sentence, if we were to somehow semantically cluster the sentences, would be the best representative of the cluster. Your output should be this sentence only without any modifications or changes to the sentence.\n\n{sentences}"

    response = await model_call(content)
    return response

async def pick_best_sentences(sentences: list[list[str]], model_call):
    tasks = [pick_best_sentence(candidate, model_call) for candidate in sentences]
    return await tqdm.gather(*tasks)

async def process_sentence(sentence: str, model_call):

    contents = """
I have a noisy speech recognition system which predicts 64 words at a time. I am going to give you its predictions in an ordered list. [UNK] indicates that the target word for that position is out-of-vocabulary.

I want you to fill in any [UNK] positions with words that you think fit well in the sequence. Do not replace anything that is not [UNK]. Your output should be formatted as a Python dictionary mapping all 64 positions (0-indexed) to words, preserving the system's predictions and replacing any [UNK] with your suggestions. Do not output anything else.

Output example:
{0: "don't", 1: "the", 2: "scowl", ..., 63: "if"}

Predictions from speech recognition system:
"""

    contents = contents + "\n" + sentence
    response = await model_call(contents)
    response = response.strip()

    try:
        # Parse response as Python dictionary
        response = ast.literal_eval(response)
        assert isinstance(response, dict), "Response is not a dictionary"
        sentence = " ".join([response[i] for i in range(64)])
        return sentence.strip().lower()
    except Exception as e:
        print(f"Error parsing response: {e}")
        print("Response:", response)
        return "Error parsing response"


async def generate_topics(sentence: str, model_call, n_topics=5, attempts=3):

    contents=f"You are helping me fill in missing words from a very low quality speech recognition system that has a limited vocabulary. In the following text, each [mask] represents a missing word. Based on the information available in the sentence, I want you to list {n_topics} possible distinct topics the sentence could be about. Try to be specific with your topics.\n\n{sentence}\n\nFormat your output in JSON format.\n\nUse this JSON schema:\n\nReturn: list[str]\nExample:\n['topic1', 'topic2', 'topic3']"

    # Make up to 3 attempts to get a valid response.
    while attempts > 0:
        success = False
        try:
            response = await model_call(contents)
            topics = response.split("[")[-1].split("]")[0]
            topics = ast.literal_eval("[" + topics + "]")
            success = True
        except Exception:
            attempts -= 1
        
        if success:
            break
    
    if attempts <= 0:
        topics = ['unknown']

    return topics

async def infill_sentences_with_topics(sentences: list[str], possible_words: list[str], topics: list[list[str]], model_call):

    tasks = []
    for i, sentence in enumerate(sentences):
        for topic in topics[i]:
            tasks.append(process_sentence(sentence, model_call, possible_words, topic))

    return await tqdm.gather(*tasks)

async def infill_sentences(sentences: list[str], model_call):
    tasks = [process_sentence(sentence, model_call) for sentence in sentences]
    return await tqdm.gather(*tasks)

async def generate_topics_sentences(sentences: list[str], model_call, n_topics=5):
    tasks = [generate_topics(sentence, model_call, n_topics) for sentence in sentences]
    return await tqdm.gather(*tasks)

def replace_unks_alt(text, vocab, unk_token="[UNK]"):
    parts = text.split(unk_token)
    result = parts[0]
    
    for i in range(1, len(parts)):
        random_word = random.choice(vocab).lower()
        result += random_word + parts[i]
    
    return result

if __name__ == "__main__":
    filled = replace_unks_alt("[UNK] cat sat [UNK] the [UNK]", ["dog", "cat", "sat", "on", "the", "sofa"])
    print(filled)

# if __name__ == "__main__":
#     from model.deepseek_infilling import model_call
#     # from model.gemini_infilling import model_call
#     # from model.claude_infilling import model_call
#     # sentences = [
#     #     "The cat [mask] on the [mask].",
#     #     "I [mask] to the store to [mask] some [mask]."
#     # ]
#     # results = asyncio.run(infill_sentences(
#     #     sentences, possible_words=["sat", "sofa", "went", "fix", "pipes"], model_call=model_call))
#     # # results = asyncio.run(generate_topics_sentences(sentences, model_call))
#     # print(results)
#     sentences = [
#         "their died [mask] houses were far on his chair asked sir when i whole ourselves at the other and some [mask] effect upon us led he front to me i [mask] at the ground [mask] whom does are dead lestrade but are never impossible to find mister peculiar [mask] up his [mask] [mask] and a [mask] [mask] had [mask] above the [mask] oh lie",
#         "the floor there was almost break off miss cases and would appeared to my [mask] experience hung any other [mask] i must [mask] been [mask] than [mask] [mask] he looked surprised in the chair [mask] houses were front on his chair asked sir where i mere lying at the office and some [mask] knife upon us what he front to me i [mask] throw"
#     ]
#     results = asyncio.run(infill_sentences(sentences, [], model_call))
#     for sentence, result in zip(sentences, results):
#         print(f"Original: {sentence}")
#         print(f"Filled: {result}")
#         print()